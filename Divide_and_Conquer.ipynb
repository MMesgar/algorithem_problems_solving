{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Divide-and-Conquer.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "TOOGJ-MuLu0p"
      ],
      "authorship_tag": "ABX9TyOGFz24GEAcNw+xWCAAdzPW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MMesgar/algorithem_problems_solving/blob/master/Divide_and_Conquer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Divide and conquer (D&C): \n",
        "A divide-and-conquer algorithm works by recursively breaking the problem down into two or more subproblems of the same or related type, until these subproblems become simple enough to be solved directly. Then one combines the results of subproblems to form the final solution. \n",
        "\n",
        "## Main difference with simple recursion:\n",
        "A subtle difference that tells a divide-and-conquer algorithm apart from other recursive algorithms is that we break the problem down into two or more subproblems in the divide-and-conquer algorithm, rather than a single smaller subproblem. The D&C recursive algorithm sometimes is called decrease and conquer instead, such as Binary Search.\n",
        "\n",
        "There are in general three steps that one can follow in order to solve the problem in a divide-and-conquer manner.\n",
        "\n",
        "1. Divide. Divide the problem S into a set of subproblems: \n",
        "${S_1, S_2, ..., S_n}$ where $nâ‰¥2$, i.e. there are usually more than one subproblem.\n",
        "\n",
        "2. Conquer. Solve each subproblem recursively. \n",
        "\n",
        "3. Combine. Combine the results of each subproblem.\n",
        "\n",
        "## D&C Template\n",
        "```python\n",
        "def divide_and_conquer( S ):\n",
        "    # (1). Divide the problem into a set of subproblems.\n",
        "    [S1, S2, ... Sn] = divide(S)\n",
        "\n",
        "    # (2). Solve the subproblem recursively,\n",
        "    #   obtain the results of subproblems as [R1, R2... Rn].\n",
        "    rets = [divide_and_conquer(Si) for Si in [S1, S2, ... Sn]]\n",
        "    [R1, R2,... Rn] = rets\n",
        "\n",
        "    # (3). combine the results from the subproblems.\n",
        "    #   and return the combined result.\n",
        "    return combine([R1, R2,... Rn])\n",
        "```\n",
        "\n",
        "As one can see from the above template, the essential part of the divide and conquer is to figure out the recurrence relationship between the subproblems and the original problem, which subsequently defines the functions of divide and combine. \n",
        " \n"
      ],
      "metadata": {
        "id": "eOaNDYqkLRBG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Master Theorem\n",
        "Master Theorem, also known as Master Method, provides asymptotic analysis (i.e. the time complexity) for many of the recursion algorithms that follow the pattern of divide-and-conquer.  \n",
        "It does not apply to all recursion algorithms. \n",
        "If we define the time complexity of the above recursion algorithm as \n",
        "$T(n)$, then we can express it as follows:\n",
        "\n",
        "$T(n) = aT(\\frac{n}{b}) + f(n)$\n",
        "\n",
        "where $f(n) \\in O(n^d)$ is the time complexity that it takes to divide the problems into subproblems and also to combine the results from the subproblems. \n",
        "\n",
        "\n",
        "\n",
        "1. If $a>b^d$ then $T(n) = O(n^{log_ba})$\n",
        "2. If $a=b^d$ then $T(n) = O(n^{log_ba} logn)$\n",
        "3. If $a < b^d$ then $T(n) = O(n^{d})$\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9vCeUUuUes6U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "# Problem: Merge Sort\n",
        "One of the classic examples of the divide-and-conquer algorithm is the merge sort algorithm. Merge sort is an efficient and general-purpose sorting algorithm.  \n",
        "\n",
        "There are two approaches to implement the merge sort algorithm: top down or bottom up. Here, we will explain the top down approach as it can be implemented naturally using recursion.\n",
        "The merge sort algorithm can be divided into three steps, like all divide-and-conquer algorithms:\n",
        "\n",
        "1. Divide. Divide the given unsorted list into several sublists.  \n",
        " \n",
        "2. Conquer. Sort each of the sublists **recursively**.  \n",
        " \n",
        "3. Combine. Merge the sorted sublists to produce new sorted list.  \n",
        "\n",
        "The recursion in step (2) would reach the base case where the input list is either empty or contains a single element. \n",
        "Now, we have reduced the problem down to a merge problem, which is much simpler to solve. Merging two sorted lists can be done in linear time complexity $O(N)$ where N is the total lengths of the two lists to merge. \n",
        "\n"
      ],
      "metadata": {
        "id": "TOOGJ-MuLu0p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def merge_sort(nums):\n",
        "    # base cases: empty or list of a single element.\n",
        "    if len(nums) <= 1:\n",
        "        return nums\n",
        "\n",
        "    # 1. divide\n",
        "    pivot = int(len(nums) / 2)\n",
        "\n",
        "    # 2. conqure\n",
        "    left_list = merge_sort(nums[0:pivot])\n",
        "    right_list = merge_sort(nums[pivot:])\n",
        "\n",
        "    # 3. combine\n",
        "    output = merge(left_list, right_list)\n",
        "\n",
        "    return output\n",
        "\n",
        "\n",
        "def merge(left_list, right_list):\n",
        "    left_cursor = right_cursor = 0\n",
        "    ret = []\n",
        "    while left_cursor < len(left_list) and right_cursor < len(right_list):\n",
        "        if left_list[left_cursor] < right_list[right_cursor]:\n",
        "            ret.append(left_list[left_cursor])\n",
        "            left_cursor += 1\n",
        "        else:\n",
        "            ret.append(right_list[right_cursor])\n",
        "            right_cursor += 1\n",
        "    \n",
        "    # append what is remained in either of the lists\n",
        "    ret.extend(left_list[left_cursor:])\n",
        "    ret.extend(right_list[right_cursor:])\n",
        "    \n",
        "    return ret"
      ],
      "metadata": {
        "id": "jTFH2-nbMoJl"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bottom-up Approach**\n",
        "In the bottom up approach, we divide the list into sublists of a single element at the beginning. Each of the sublists is then sorted already. Then from this point on, we merge the sublists two at a time until a single list remains. \n",
        "\n",
        "**Time complexity**\n",
        "The overall time complexity of the merge sort algorithm is $O(NlogN)$, where \n",
        "N is the length of the input list. To calculate the complexity, we break it down to the following steps. (1) We recursively divide the input list into two sublists, until a sublist with single element remains. This dividing step computes the midpoint of each of the sublists, which takes $O(1)$\n",
        " time. This step is repeated N times until a single element remains, therefore the total time complexity is $O(N)$. Then, we repetitively merge the sublists, until one single list remains.  Since in the recursion tree, there are a total of N elements on each level. Therefore, it takes $O(N)$\n",
        "time for the merging process to complete on each level. And since there are a total of $log (N)$ levels, the overall complexity of the merge process is $\n",
        "O(NlogN)$.\n",
        "\n",
        "The space complexity of the merge sort algorithm is \n",
        "$O(N)$, where $N$ is the length of the input list, since we need to keep the sublists as well as the buffer to hold the merge results at each round of merge process."
      ],
      "metadata": {
        "id": "mdP8jgtFNRkL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "# Problem: Quick sort \n",
        "Quick sort is another classical divide-and-conquer algorithm for sorting. When implemented well, quick sort algorithm can be two or three times faster than its predecessors and competitors such as merge sort, which is why it gains its name. \n",
        "\n",
        "\n",
        "In detail, given a list of values to sort, the quick sort algorithm works in the following steps:\n",
        "\n",
        "1.   First, it selects a value from the list, which serves as a pivot value to divide the list into two sublists. One sublist contains all the values that are less than the pivot value, while the other sublist contains the values that are greater than or equal to the pivot value. This process is also called partitioning. The strategy of choosing a pivot value can vary. Typically, one can choose the first element in the list as the pivot, or randomly pick an element from the list.\n",
        "\n",
        "2. After the partitioning process, the original list is then reduced into two smaller sublists. We then recursively sort the two sublists.\n",
        "\n",
        "3. After the partitioning process, we are sure that all elements in one sublist are less or equal than any element in another sublist. Therefore, we can simply concatenate the two sorted sublists that we obtain in step [2] to obtain the final sorted list. \n",
        "\n",
        "The base cases of the recursion in step [2] are either when the input list is empty or the empty list contains only a single element. In either case, the input list can be considered as sorted already.\n",
        "\n"
      ],
      "metadata": {
        "id": "SLaOZPl4cX7Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def quicksort(lst):\n",
        "    \"\"\"\n",
        "    Sorts an array in the ascending order in O(n log n) time\n",
        "    :param nums: a list of numbers\n",
        "    :return: the sorted list\n",
        "    \"\"\"\n",
        "    n = len(lst)\n",
        "    qsort(lst, 0, n - 1)\n",
        "\n",
        "def qsort(lst, lo, hi):\n",
        "    \"\"\"\n",
        "    Helper\n",
        "    :param lst: the list to sort\n",
        "    :param lo:  the index of the first element in the list\n",
        "    :param hi:  the index of the last element in the list\n",
        "    :return: the sorted list\n",
        "    \"\"\"\n",
        "    if lo < hi:\n",
        "        p = partition(lst, lo, hi)\n",
        "        qsort(lst, lo, p - 1)\n",
        "        qsort(lst, p + 1, hi)\n",
        "\n",
        "def partition(lst, lo, hi):\n",
        "    \"\"\"\n",
        "    Picks the last element hi as a pivot\n",
        "     and returns the index of pivot value in the sorted array\n",
        "    \"\"\"\n",
        "    pivot = lst[hi]\n",
        "    i = lo\n",
        "    for j in range(lo, hi):\n",
        "        if lst[j] < pivot:\n",
        "            lst[i], lst[j] = lst[j], lst[i]\n",
        "            i += 1\n",
        "    lst[i], lst[hi] = lst[hi], lst[i]\n",
        "    return i"
      ],
      "metadata": {
        "id": "hGE5zXXxdcEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Depending on the pivot values, the time complexity of the quick sort algorithm can vary from $O(Nlog_2N)$ in the best case (where the pivot value happens to be median value of the list) and \n",
        "O(N^2)in the worst case (where the pivot value happens to be the extreme value of the list), i.e. either the smallest or the biggest element in the list,, with N as the length of the list. \n",
        "\n",
        "On average, as proved mathematically, the time complexity of quick sort is $O(Nlog_2N)$."
      ],
      "metadata": {
        "id": "Q6c8lblFd9GA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "# Problem: [Quickselect](https://https://en.wikipedia.org/wiki/Quickselect)\n",
        "select the kth largest/smallest element in an unsorted list. \n",
        "Given an integer array nums and an integer k, return the kth largest element in the array.\n",
        "Note that it is the kth largest element in the sorted order, not the kth distinct element. \n",
        "\n",
        "```python\n",
        "Input: nums = [3,2,1,5,6,4], k = 2\n",
        "Output: 5\n",
        "\n",
        "Input: nums = [3,2,3,1,2,4,5,5,6], k = 4\n",
        "Output: 4\n",
        "```\n",
        "\n",
        "Constraints:\n",
        "\n",
        "$1 <= k <= nums.length <= 104$\n",
        "\n",
        "$-104 <= nums[i] <= 104$\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "I2_Igw72jUVD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "class Solution:\n",
        "    def findKthLargest(self, nums: List[int], k: int) -> int:\n",
        "        def select(left, right, k_smallest):\n",
        "            \n",
        "            if left == right:\n",
        "                return nums[left]\n",
        "            \n",
        "            # select a random pivot\n",
        "            pivot_index = random.randint(left, right)\n",
        "            \n",
        "            # find the pivot position in a sorted list\n",
        "            pivot_index = partition(left, right, pivot_index)\n",
        "            \n",
        "            # the pivot is in its final sorted position\n",
        "            if k_smallest == pivot_index:\n",
        "                return nums[pivot_index]\n",
        "            # go left\n",
        "            elif k_smallest < pivot_index:\n",
        "                return select(left, pivot_index-1, k_smallest)\n",
        "            # go right\n",
        "            else:\n",
        "                return select(pivot_index+1, right, k_smallest)\n",
        "            # kth largest is (n - k)th smallest \n",
        "        \n",
        "        def partition(left, right, pivot_index):\n",
        "            pivot = nums[pivot_index]\n",
        "            \n",
        "            # move pivot to the end\n",
        "            nums[pivot_index], nums[right] = nums[right], nums[pivot_index]\n",
        "            \n",
        "            # move all smaller elements to the left\n",
        "            store_index = left\n",
        "            for i in range(left, right):\n",
        "                if nums[i] < pivot:\n",
        "                    nums[store_index], nums[i] = nums[i] ,  nums[store_index]\n",
        "                    store_index += 1\n",
        "                    \n",
        "            # move pivot to tis final place\n",
        "            nums[right], nums[store_index] = nums[store_index], nums[right]\n",
        "            \n",
        "            return store_index\n",
        "        \n",
        "        return select(0, len(nums)-1, len(nums)-k)\n",
        "            "
      ],
      "metadata": {
        "id": "CgY4MFdvjvBE"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "# Problem: Validate Binary Search Tree\n",
        "**Sometimes**, tree related problems can be solved using divide-and-conquer algorithms.\n",
        "\n",
        "\n",
        "Given the root of a binary tree, determine if it is a valid binary search tree (BST).\n",
        "\n",
        "A valid BST is defined as follows:\n",
        "\n",
        "\n",
        "*   All values on the left subtree of a node should be less than the value of the node.\n",
        "\n",
        "*   All values on the right subtree of a node should be greater than the value of the node.\n",
        "* Both the left and right subtrees must also be binary search trees.\n",
        "\n",
        "```python\n",
        "Input: root = [2,1,3]\n",
        "Output: true\n",
        "\n",
        "Input: root = [5,1,4,null,null,3,6]\n",
        "Output: false\n",
        "Explanation: The root node's value is 5 but its right child's value is 4.\n",
        "```\n",
        "\n",
        "Constraints:\n",
        "\n",
        "The number of nodes in the tree is in the range $[1, 104]$.\n",
        "\n",
        "$-231 <= Node.val <= 231 - 1$\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "X25vcht2OywV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Optional\n",
        "# Definition for a binary tree node.\n",
        "class TreeNode:\n",
        "    def __init__(self, val=0, left=None, right=None):\n",
        "        self.val = val\n",
        "        self.left = left\n",
        "        self.right = right\n",
        "class Solution:\n",
        "    def isValidBST(self, root: Optional[TreeNode]) -> bool:\n",
        "        # base case:\n",
        "        if root is None:\n",
        "            return True\n",
        "        if root.left is None and root.right is None:\n",
        "            return True\n",
        "        if root.left is not None and not(root.val > self.max_value(root.left)): \n",
        "            return False\n",
        "        if root.right is not None and not(root.val < self.min_value(root.right)):\n",
        "            return False\n",
        "        \n",
        "        # divide & Conqure\n",
        "        is_left_tree_bst = self.isValidBST(root.left)\n",
        "        is_right_tree_bst = self.isValidBST(root.right)\n",
        "        \n",
        "        # combine\n",
        "        output = is_left_tree_bst and is_right_tree_bst\n",
        "        return output\n",
        "    \n",
        "    def min_value(self, root):\n",
        "        while root.left:\n",
        "            root = root.left\n",
        "        return root.val\n",
        "    def max_value(self, root):\n",
        "        while root.right:\n",
        "            root = root.right\n",
        "        return root.val"
      ],
      "metadata": {
        "id": "1l1w_PWLNQtT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#The idea above could be implemented as a recursion. \n",
        "# One compares the node value with its upper and lower limits if they are available.\n",
        "# Then one repeats the same step recursively for left and right subtrees.\n",
        "from typing import Optional\n",
        "#Definition for a binary tree node.\n",
        "class TreeNode:\n",
        "    def __init__(self, val=0, left=None, right=None):\n",
        "        self.val = val\n",
        "        self.left = left\n",
        "        self.right = right\n",
        "class Solution:\n",
        "    def isValidBST(self, root: Optional[TreeNode]) -> bool:\n",
        "        def validate(node, low=-math.inf, high=math.inf):\n",
        "            if not node:\n",
        "                return True\n",
        "            if not (low < node.val and node.val < high):\n",
        "                return False\n",
        "            is_left_tree_bst = validate(node.left, low=low, high=node.val)\n",
        "            is_right_tree_bst = validate(node.right, low=node.val, high=high)\n",
        "            return is_left_tree_bst and is_right_tree_bst\n",
        "        return validate(root)\n",
        "            "
      ],
      "metadata": {
        "id": "BBeH5Ei0Z6m9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "CJSGqopPbn-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "# Problem: Maximum Depth of Binary Tree\n",
        "Given the root of a binary tree, return its maximum depth.\n",
        "A binary tree's maximum depth is the number of nodes along the longest path from the root node down to the farthest leaf node. \n",
        "\n",
        "```python\n",
        "Input: root = [3,9,20,null,null,15,7]\n",
        "Output: 3\n",
        "```\n",
        "\n",
        "The number of nodes in the tree is in the range $[0, 104]$.\n",
        "\n",
        "$-100 <= Node.val <= 100$\n"
      ],
      "metadata": {
        "id": "mQNmFBkUg5RT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Solution:\n",
        "    def maxDepth(self, root: Optional[TreeNode]) -> int:\n",
        "        # base case\n",
        "        if root is None:\n",
        "            return 0\n",
        "        \n",
        "        # divide and conqure\n",
        "        max_depth_left_tree = self.maxDepth(root.left)\n",
        "        max_depth_right_tree = self.maxDepth(root.right)\n",
        "        \n",
        "        # combine\n",
        "        return 1+ max([max_depth_left_tree,max_depth_right_tree])"
      ],
      "metadata": {
        "id": "8_gNoxunhMPd"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can figure out the values for the parameters in Master Theorem,  i.e. b=2 (problem divided into halves),  a=2 (both subproblems needed to be solved), and f(n)=O(1) therefore d=0. \n",
        "In particular, the reason behind f(n)=O(1) is twofold: 1) The effort to split the problems in DFS is constant, since the input is already organized as a collection of subproblems, i.e. children subtrees. 2) The effort to combine the results from the recursion calls is also constant.  \n",
        "\n",
        "As a result, by applying the Master Theorem, we can obtain the time complexity of DFS recursion algorithm, as follows:\n",
        "\n",
        "Since a=2,b=2,d=0, so T(n)=O(n).\n",
        "\n",
        "As we know, the time complexity for DFS recursion algorithm is indeed O(n)."
      ],
      "metadata": {
        "id": "32pmI7V5iGke"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "qWzBSJYXiAdY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}